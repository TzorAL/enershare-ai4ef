{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 198 entries, 0 to 197\n",
      "Data columns (total 83 columns):\n",
      " #   Column                                        Non-Null Count  Dtype  \n",
      "---  ------                                        --------------  -----  \n",
      " 0   Project number                                198 non-null    object \n",
      " 1   The date                                      198 non-null    object \n",
      " 2   Region                                        198 non-null    object \n",
      " 3   The town/village                              191 non-null    object \n",
      " 4   Home address                                  198 non-null    object \n",
      " 5   County/City                                   198 non-null    object \n",
      " 6   Initial year of exploitation                  198 non-null    int64  \n",
      " 7   Building Total Area                           198 non-null    float64\n",
      " 8   Room volume                                   198 non-null    float64\n",
      " 9   Average floor height                          198 non-null    float64\n",
      " 10  Reference area                                198 non-null    float64\n",
      " 11  Above-ground floors                           198 non-null    int64  \n",
      " 12  Underground floor                             198 non-null    int64  \n",
      " 13  Mansard                                       198 non-null    int64  \n",
      " 14  Roof floor                                    198 non-null    int64  \n",
      " 15  Initial energy class                          198 non-null    object \n",
      " 16  Energy consumption before                     198 non-null    float64\n",
      " 17  Heat energy consumption before                198 non-null    float64\n",
      " 18  Carbon dioxide emissions before               197 non-null    float64\n",
      " 19  Carrying out construction works               198 non-null    int64  \n",
      " 20  Reconstruction of engineering systems         198 non-null    int64  \n",
      " 21  Water heating system                          198 non-null    int64  \n",
      " 22  Heat installation                             198 non-null    int64  \n",
      " 23  Energy audit number                           198 non-null    object \n",
      " 24  Energy class after                            198 non-null    object \n",
      " 25  Heat energy consumption after                 198 non-null    int64  \n",
      " 26  Consumption for hot water after               198 non-null    int64  \n",
      " 27  Consumption for mechanical ventilation after  198 non-null    int64  \n",
      " 28  Consumption for lighting after                198 non-null    int64  \n",
      " 29  Consumption for cooling after                 198 non-null    int64  \n",
      " 30  Energy consumption after                      198 non-null    int64  \n",
      " 31  Heat saving for heating                       198 non-null    float64\n",
      " 32  Total energy consumption saving               198 non-null    float64\n",
      " 33  Saving of heat energy                         198 non-null    float64\n",
      " 34  Primary non-renewable energy                  197 non-null    float64\n",
      " 35  Primary total energy consumption              198 non-null    float64\n",
      " 36  Almost zero energy building                   198 non-null    object \n",
      " 37  Carbon dioxide emission tons after            198 non-null    float64\n",
      " 38  Carbon dioxide emission after                 198 non-null    float64\n",
      " 39  Area of the external surface                  179 non-null    float64\n",
      " 40  Average heat transfer coefficient             179 non-null    float64\n",
      " 41  Average heat transfer coefficient_1           179 non-null    float64\n",
      " 42  Building calculated heat loss coefficient     179 non-null    float64\n",
      " 43  Building allowable heat loss coefficient      179 non-null    float64\n",
      " 44  Indoor temperature heating                    179 non-null    float64\n",
      " 45  Indoor temperature for cooling                179 non-null    object \n",
      " 46  Air exchange rate                             179 non-null    float64\n",
      " 47  Ventilation heat loss coefficient             177 non-null    float64\n",
      " 48  Energy resource for heating 1                 179 non-null    object \n",
      " 49  Energy resource for heating 2                 178 non-null    object \n",
      " 50  Energy resource for hot water 1               179 non-null    object \n",
      " 51  Energy resource for hot water 2               178 non-null    object \n",
      " 52  Energy resource for ventilation               178 non-null    object \n",
      " 53  Energy resource for cooling 1                 179 non-null    object \n",
      " 54  Energy resource for cooling 2                 179 non-null    object \n",
      " 55  CO2 emission factor for heating 1             179 non-null    float64\n",
      " 56  CO2 emission factor for heating 2             179 non-null    object \n",
      " 57  CO2 emission factor for hot water 1           179 non-null    object \n",
      " 58  CO2 emission factor for hot water 2           179 non-null    object \n",
      " 59  CO2 emission factor for ventilation           179 non-null    object \n",
      " 60  CO2 emission factor for cooling 1             179 non-null    object \n",
      " 61  CO2 emission factor for cooling 2             179 non-null    object \n",
      " 62  Non-renewable factor for heating 1            179 non-null    float64\n",
      " 63  Non-renewable factor for heating 2            179 non-null    object \n",
      " 64  Non-renewable factor for water 1              179 non-null    object \n",
      " 65  Non-renewable factor for water 2              179 non-null    object \n",
      " 66  Non-renewable factor for ventilation          179 non-null    object \n",
      " 67  Non-renewable factor for cooling 1            179 non-null    object \n",
      " 68  Non-renewable factor for cooling 2            179 non-null    object \n",
      " 69  Renewable factor for heating 1                179 non-null    float64\n",
      " 70  Renewable factor for heating 2                179 non-null    object \n",
      " 71  Renewable factor for water 1                  179 non-null    object \n",
      " 72  Renewable factor for water 2                  179 non-null    object \n",
      " 73  Renewable factor for ventilation              179 non-null    object \n",
      " 74  Renewable factor for cooling 1                179 non-null    object \n",
      " 75  Renewable factor for cooling 2                179 non-null    object \n",
      " 76  Total factor for heating 1                    179 non-null    float64\n",
      " 77  Total factor for heating 2                    179 non-null    object \n",
      " 78  Total factor for water 1                      179 non-null    object \n",
      " 79  Total factor for water 2                      179 non-null    object \n",
      " 80  Total factor for ventilation                  179 non-null    object \n",
      " 81  Total factor for cooling 1                    179 non-null    object \n",
      " 82  Total factor for cooling 2                    179 non-null    object \n",
      "dtypes: float64(26), int64(15), object(42)\n",
      "memory usage: 128.5+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('./EF_comp.csv')\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 198 entries, 0 to 197\n",
      "Data columns (total 11 columns):\n",
      " #   Column                                 Non-Null Count  Dtype  \n",
      "---  ------                                 --------------  -----  \n",
      " 0   Building Total Area                    198 non-null    float64\n",
      " 1   Reference area                         198 non-null    float64\n",
      " 2   Above-ground floors                    198 non-null    int64  \n",
      " 3   Underground floor                      198 non-null    int64  \n",
      " 4   Initial energy class                   198 non-null    object \n",
      " 5   Energy consumption before              198 non-null    float64\n",
      " 6   Carrying out construction works        198 non-null    int64  \n",
      " 7   Reconstruction of engineering systems  198 non-null    int64  \n",
      " 8   Water heating system                   198 non-null    int64  \n",
      " 9   Heat installation                      198 non-null    int64  \n",
      " 10  Energy class after                     198 non-null    object \n",
      "dtypes: float64(3), int64(6), object(2)\n",
      "memory usage: 17.1+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "feature_cols = ['Building Total Area','Reference area','Above-ground floors',\n",
    "                'Underground floor','Energy consumption before',\n",
    "                'Initial energy class ','Energy class after']\n",
    "target_cols = ['Carrying out construction works ','Reconstruction of engineering systems',\n",
    "                'Heat installation','Water heating system']\n",
    "\n",
    "categorical_cols = ['Above-ground floors','Underground floor',\n",
    "                    'Carrying out construction works',\n",
    "                    'Reconstruction of engineering systems',\n",
    "                    'Heat installation','Water heating system']\n",
    "\n",
    "df = df[df.columns[df.columns.isin(feature_cols+target_cols)]]\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pandas.api.types import is_string_dtype\n",
    "from pandas.api.types import is_numeric_dtype\n",
    "\n",
    "for col in df.columns:\n",
    "    if is_numeric_dtype(df[col]):\n",
    "        df[[col]] = MinMaxScaler().fit_transform(df[[col]])\n",
    "\n",
    "for col in df.columns:\n",
    "    if is_string_dtype(df[col]):\n",
    "        df[col] = LabelEncoder().fit_transform(df[col])\n",
    "\n",
    "\n",
    "Xfeatures = df[feature_cols]\n",
    "ylabels = df[target_cols]\n",
    "\n",
    "train_X,test_X,train_Y,test_Y = train_test_split(Xfeatures,ylabels,test_size=0.2,random_state=7)\n",
    "train_X, validation_X, train_Y, validation_Y = train_test_split(train_X, train_Y, test_size=0.25, random_state=1, shuffle=True) # 0.25 x 0.8 = 0.2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "classifier  = MLPClassifier(hidden_layer_sizes=(150,100,50), max_iter=500, activation = 'relu', \n",
    "                            solver='adam', shuffle=True, random_state=1, #,verbose=True, early_stopping=True\n",
    "                            learning_rate='adaptive').fit(train_X, train_Y)\n",
    "classifier.fit(train_X, train_Y)\n",
    "pred_Y = classifier.predict(validation_X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.225\n",
      "Precision: 0.6909090909090909\n",
      "Recall: 0.6129032258064516\n",
      "F1-Score: 0.6495726495726496\n",
      "Hamming Loss: 0.25625\n",
      "Jaccard Index: 0.4810126582278481\n",
      "Average Precision: 0.5734604105571848\n",
      "Confusion Matrix:\n",
      " [[31  7]\n",
      " [ 2  0]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.82      0.87        38\n",
      "           1       0.33      0.35      0.34        20\n",
      "           2       0.00      0.00      0.00         3\n",
      "           3       0.00      0.00      0.00         1\n",
      "\n",
      "   micro avg       0.69      0.61      0.65        62\n",
      "   macro avg       0.32      0.29      0.30        62\n",
      "weighted avg       0.68      0.61      0.65        62\n",
      " samples avg       0.71      0.65      0.63        62\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, hamming_loss, jaccard_score, average_precision_score\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, auc, precision_recall_curve, confusion_matrix, classification_report\n",
    "\n",
    "val = pd.DataFrame(pred_Y,columns=['Carrying out construction works', 'Reconstruction of engineering systems', 'Heat installation','Water heating system'])\n",
    "\n",
    "accuracy = accuracy_score(test_Y.values, pred_Y)\n",
    "\n",
    "# Precision, Recall, F1-Score\n",
    "precision = precision_score(test_Y.values, pred_Y, average='micro')\n",
    "recall = recall_score(test_Y.values, pred_Y, average='micro')\n",
    "f1 = f1_score(test_Y.values, pred_Y, average='micro')\n",
    "\n",
    "# Hamming Loss\n",
    "hamming_loss_value = hamming_loss(test_Y.values, pred_Y)\n",
    "\n",
    "# Jaccard Index\n",
    "jaccard = jaccard_score(test_Y.values, pred_Y, average='micro')\n",
    "\n",
    "# Average Precision Score\n",
    "average_precision = average_precision_score(test_Y.values, pred_Y, average='micro')\n",
    "\n",
    "# Confusion Matrix\n",
    "confusion = confusion_matrix(test_Y.values.argmax(axis=1), pred_Y.argmax(axis=1))\n",
    "\n",
    "# Classification Report\n",
    "class_report = classification_report(test_Y.values, pred_Y)\n",
    "\n",
    "# Print the computed metrics\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1-Score:\", f1)\n",
    "print(\"Hamming Loss:\", hamming_loss_value)\n",
    "print(\"Jaccard Index:\", jaccard)\n",
    "print(\"Average Precision:\", average_precision)\n",
    "print(\"Confusion Matrix:\\n\", confusion)\n",
    "print(\"Classification Report:\\n\", class_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "472"
      ]
     },
     "execution_count": 328,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_Y.values.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier() {'KNN__n_neighbors': [1, 3, 5, 7, 9, 11, 13, 15], 'KNN__weights': ['uniform', 'distance']} KNN\n",
      "\n",
      "\n",
      "Tuning hyper-parameters, based on accuracy for KNN with parameter grid:\n",
      " {'KNN__n_neighbors': [1, 3, 5, 7, 9, 11, 13, 15], 'KNN__weights': ['uniform', 'distance']}\n",
      "\n",
      "Mean performance of each parameter combination based on Cross Validation\n",
      "    KNN__n_neighbors KNN__weights     Score\n",
      "0                  1      uniform  0.356522\n",
      "1                  1     distance  0.356522\n",
      "2                  3      uniform  0.331522\n",
      "3                  3     distance  0.348551\n",
      "4                  5      uniform  0.356159\n",
      "5                  5     distance  0.381522\n",
      "6                  7      uniform  0.407246\n",
      "7                  7     distance  0.381159\n",
      "8                  9      uniform  0.406522\n",
      "9                  9     distance  0.389855\n",
      "10                11      uniform  0.389130\n",
      "11                11     distance  0.397826\n",
      "12                13      uniform  0.346377\n",
      "13                13     distance  0.406159\n",
      "14                15      uniform  0.328986\n",
      "15                15     distance  0.388768\n",
      "\n",
      "Best parameters set found on training set:\n",
      "{'KNN__n_neighbors': 7, 'KNN__weights': 'uniform'}\n",
      "\n",
      "The scores are computed on the full evaluation set:\n",
      "Accuracy: 0.425\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.94444   0.89474   0.91892        38\n",
      "           1    0.60000   0.60000   0.60000        20\n",
      "           2    0.00000   0.00000   0.00000         3\n",
      "           3    0.00000   0.00000   0.00000         1\n",
      "\n",
      "   micro avg    0.82143   0.74194   0.77966        62\n",
      "   macro avg    0.38611   0.37368   0.37973        62\n",
      "weighted avg    0.77240   0.74194   0.75676        62\n",
      " samples avg    0.85000   0.79583   0.78083        62\n",
      "\n",
      "OneVsRestClassifier(estimator=SVC()) {'OVR__estimator__kernel': ['rbf', 'linear'], 'OVR__estimator__gamma': ['scale', 'auto'], 'OVR__estimator__C': [10, 100, 1000]} OVR\n",
      "\n",
      "\n",
      "Tuning hyper-parameters, based on accuracy for OVR with parameter grid:\n",
      " {'OVR__estimator__kernel': ['rbf', 'linear'], 'OVR__estimator__gamma': ['scale', 'auto'], 'OVR__estimator__C': [10, 100, 1000]}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean performance of each parameter combination based on Cross Validation\n",
      "    OVR__estimator__C OVR__estimator__gamma OVR__estimator__kernel     Score\n",
      "0                  10                 scale                    rbf  0.422464\n",
      "1                  10                 scale                 linear  0.378986\n",
      "2                  10                  auto                    rbf  0.405797\n",
      "3                  10                  auto                 linear  0.378986\n",
      "4                 100                 scale                    rbf  0.381159\n",
      "5                 100                 scale                 linear  0.405797\n",
      "6                 100                  auto                    rbf  0.372826\n",
      "7                 100                  auto                 linear  0.405797\n",
      "8                1000                 scale                    rbf  0.355072\n",
      "9                1000                 scale                 linear  0.380435\n",
      "10               1000                  auto                    rbf  0.355072\n",
      "11               1000                  auto                 linear  0.380435\n",
      "\n",
      "Best parameters set found on training set:\n",
      "{'OVR__estimator__C': 10, 'OVR__estimator__gamma': 'scale', 'OVR__estimator__kernel': 'rbf'}\n",
      "\n",
      "The scores are computed on the full evaluation set:\n",
      "Accuracy: 0.55\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.94872   0.97368   0.96104        38\n",
      "           1    0.65217   0.75000   0.69767        20\n",
      "           2    0.00000   0.00000   0.00000         3\n",
      "           3    0.00000   0.00000   0.00000         1\n",
      "\n",
      "   micro avg    0.83871   0.83871   0.83871        62\n",
      "   macro avg    0.40022   0.43092   0.41468        62\n",
      "weighted avg    0.79185   0.83871   0.81408        62\n",
      " samples avg    0.85000   0.86667   0.83000        62\n",
      "\n",
      "DecisionTreeClassifier() {'DT__criterion': ['entropy'], 'DT__max_depth': [6], 'DT__min_samples_leaf': [1], 'DT__min_samples_split': [4]} DT\n",
      "\n",
      "\n",
      "Tuning hyper-parameters, based on accuracy for DT with parameter grid:\n",
      " {'DT__criterion': ['entropy'], 'DT__max_depth': [6], 'DT__min_samples_leaf': [1], 'DT__min_samples_split': [4]}\n",
      "\n",
      "Mean performance of each parameter combination based on Cross Validation\n",
      "  DT__criterion  DT__max_depth  DT__min_samples_leaf  DT__min_samples_split  \\\n",
      "0       entropy              6                     1                      4   \n",
      "\n",
      "     Score  \n",
      "0  0.44058  \n",
      "\n",
      "Best parameters set found on training set:\n",
      "{'DT__criterion': 'entropy', 'DT__max_depth': 6, 'DT__min_samples_leaf': 1, 'DT__min_samples_split': 4}\n",
      "\n",
      "The scores are computed on the full evaluation set:\n",
      "Accuracy: 0.4\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.93750   0.78947   0.85714        38\n",
      "           1    0.59259   0.80000   0.68085        20\n",
      "           2    0.00000   0.00000   0.00000         3\n",
      "           3    1.00000   1.00000   1.00000         1\n",
      "\n",
      "   micro avg    0.77049   0.75806   0.76423        62\n",
      "   macro avg    0.63252   0.64737   0.63450        62\n",
      "weighted avg    0.78188   0.75806   0.76110        62\n",
      " samples avg    0.79167   0.79583   0.74833        62\n",
      "\n",
      "RandomForestClassifier(n_jobs=-1) {'RF__n_estimators': [200, 600], 'RF__max_depth': [4, 10, None], 'RF__min_samples_leaf': [1, 2, 5]} RF\n",
      "\n",
      "\n",
      "Tuning hyper-parameters, based on accuracy for RF with parameter grid:\n",
      " {'RF__n_estimators': [200, 600], 'RF__max_depth': [4, 10, None], 'RF__min_samples_leaf': [1, 2, 5]}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean performance of each parameter combination based on Cross Validation\n",
      "    RF__max_depth  RF__min_samples_leaf  RF__n_estimators     Score\n",
      "0             4.0                     1               200  0.474275\n",
      "1             4.0                     1               600  0.465580\n",
      "2             4.0                     2               200  0.465942\n",
      "3             4.0                     2               600  0.448913\n",
      "4             4.0                     5               200  0.431522\n",
      "5             4.0                     5               600  0.439855\n",
      "6            10.0                     1               200  0.414855\n",
      "7            10.0                     1               600  0.422826\n",
      "8            10.0                     2               200  0.448913\n",
      "9            10.0                     2               600  0.439855\n",
      "10           10.0                     5               200  0.431522\n",
      "11           10.0                     5               600  0.431522\n",
      "12            NaN                     1               200  0.406159\n",
      "13            NaN                     1               600  0.413768\n",
      "14            NaN                     2               200  0.440217\n",
      "15            NaN                     2               600  0.431522\n",
      "16            NaN                     5               200  0.456884\n",
      "17            NaN                     5               600  0.439855\n",
      "\n",
      "Best parameters set found on training set:\n",
      "{'RF__max_depth': 4, 'RF__min_samples_leaf': 1, 'RF__n_estimators': 200}\n",
      "\n",
      "The scores are computed on the full evaluation set:\n",
      "Accuracy: 0.45\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.94872   0.97368   0.96104        38\n",
      "           1    0.56000   0.70000   0.62222        20\n",
      "           2    0.00000   0.00000   0.00000         3\n",
      "           3    0.00000   0.00000   0.00000         1\n",
      "\n",
      "   micro avg    0.79688   0.82258   0.80952        62\n",
      "   macro avg    0.37718   0.41842   0.39582        62\n",
      "weighted avg    0.76212   0.82258   0.78974        62\n",
      " samples avg    0.82500   0.87083   0.80583        62\n",
      "\n",
      "MLPClassifier(learning_rate='adaptive', max_iter=500) {'MLP__hidden_layer_sizes': [150, 100, 50], 'MLP__activation': ['relu', 'logistic', 'tanh'], 'MLP__solver': ['adam', 'lbfgs', 'sgd']} MLP\n",
      "\n",
      "\n",
      "Tuning hyper-parameters, based on accuracy for MLP with parameter grid:\n",
      " {'MLP__hidden_layer_sizes': [150, 100, 50], 'MLP__activation': ['relu', 'logistic', 'tanh'], 'MLP__solver': ['adam', 'lbfgs', 'sgd']}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean performance of each parameter combination based on Cross Validation\n",
      "   MLP__activation  MLP__hidden_layer_sizes MLP__solver     Score\n",
      "0             relu                      150        adam  0.389130\n",
      "1             relu                      150       lbfgs  0.321739\n",
      "2             relu                      150         sgd  0.380072\n",
      "3             relu                      100        adam  0.422464\n",
      "4             relu                      100       lbfgs  0.356884\n",
      "5             relu                      100         sgd  0.397464\n",
      "6             relu                       50        adam  0.413768\n",
      "7             relu                       50       lbfgs  0.381884\n",
      "8             relu                       50         sgd  0.363043\n",
      "9         logistic                      150        adam  0.396739\n",
      "10        logistic                      150       lbfgs  0.356522\n",
      "11        logistic                      150         sgd  0.329348\n",
      "12        logistic                      100        adam  0.414493\n",
      "13        logistic                      100       lbfgs  0.398188\n",
      "14        logistic                      100         sgd  0.329348\n",
      "15        logistic                       50        adam  0.396739\n",
      "16        logistic                       50       lbfgs  0.381159\n",
      "17        logistic                       50         sgd  0.329348\n",
      "18            tanh                      150        adam  0.405797\n",
      "19            tanh                      150       lbfgs  0.355435\n",
      "20            tanh                      150         sgd  0.388406\n",
      "21            tanh                      100        adam  0.405797\n",
      "22            tanh                      100       lbfgs  0.305435\n",
      "23            tanh                      100         sgd  0.405435\n",
      "24            tanh                       50        adam  0.389130\n",
      "25            tanh                       50       lbfgs  0.389493\n",
      "26            tanh                       50         sgd  0.379710\n",
      "\n",
      "Best parameters set found on training set:\n",
      "{'MLP__activation': 'relu', 'MLP__hidden_layer_sizes': 100, 'MLP__solver': 'adam'}\n",
      "\n",
      "The scores are computed on the full evaluation set:\n",
      "Accuracy: 0.45\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.94737   0.94737   0.94737        38\n",
      "           1    0.57692   0.75000   0.65217        20\n",
      "           2    0.00000   0.00000   0.00000         3\n",
      "           3    0.00000   0.00000   0.00000         1\n",
      "\n",
      "   micro avg    0.79688   0.82258   0.80952        62\n",
      "   macro avg    0.38107   0.42434   0.39989        62\n",
      "weighted avg    0.76675   0.82258   0.79102        62\n",
      " samples avg    0.81250   0.85417   0.79667        62\n",
      "\n",
      "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...) {'XGB__learning_rate': [0.1, 0.2, 0.3], 'XGB__max_depth': [1, 2, 3, 4, 5, 6], 'XGB__min_child_weight': [1, 2], 'XGB__subsample': [1.0, 0.5, 0.1], 'XGB__n_estimators': [200, 600]} XGB\n",
      "\n",
      "\n",
      "Tuning hyper-parameters, based on accuracy for XGB with parameter grid:\n",
      " {'XGB__learning_rate': [0.1, 0.2, 0.3], 'XGB__max_depth': [1, 2, 3, 4, 5, 6], 'XGB__min_child_weight': [1, 2], 'XGB__subsample': [1.0, 0.5, 0.1], 'XGB__n_estimators': [200, 600]}\n",
      "\n",
      "Mean performance of each parameter combination based on Cross Validation\n",
      "     XGB__learning_rate  XGB__max_depth  XGB__min_child_weight  \\\n",
      "0                   0.1               1                      1   \n",
      "1                   0.1               1                      1   \n",
      "2                   0.1               1                      1   \n",
      "3                   0.1               1                      1   \n",
      "4                   0.1               1                      1   \n",
      "..                  ...             ...                    ...   \n",
      "211                 0.3               6                      2   \n",
      "212                 0.3               6                      2   \n",
      "213                 0.3               6                      2   \n",
      "214                 0.3               6                      2   \n",
      "215                 0.3               6                      2   \n",
      "\n",
      "     XGB__n_estimators  XGB__subsample     Score  \n",
      "0                  200             1.0  0.380072  \n",
      "1                  200             0.5  0.448551  \n",
      "2                  200             0.1  0.422826  \n",
      "3                  600             1.0  0.363768  \n",
      "4                  600             0.5  0.415217  \n",
      "..                 ...             ...       ...  \n",
      "211                200             0.5  0.432246  \n",
      "212                200             0.1  0.337681  \n",
      "213                600             1.0  0.432609  \n",
      "214                600             0.5  0.406884  \n",
      "215                600             0.1  0.406522  \n",
      "\n",
      "[216 rows x 6 columns]\n",
      "\n",
      "Best parameters set found on training set:\n",
      "{'XGB__learning_rate': 0.2, 'XGB__max_depth': 2, 'XGB__min_child_weight': 2, 'XGB__n_estimators': 200, 'XGB__subsample': 0.5}\n",
      "\n",
      "The scores are computed on the full evaluation set:\n",
      "Accuracy: 0.475\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.94286   0.86842   0.90411        38\n",
      "           1    0.58333   0.70000   0.63636        20\n",
      "           2    0.00000   0.00000   0.00000         3\n",
      "           3    0.00000   0.00000   0.00000         1\n",
      "\n",
      "   micro avg    0.79661   0.75806   0.77686        62\n",
      "   macro avg    0.38155   0.39211   0.38512        62\n",
      "weighted avg    0.76605   0.75806   0.75941        62\n",
      " samples avg    0.81250   0.80417   0.76583        62\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import metrics\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import confusion_matrix, plot_confusion_matrix\n",
    "\n",
    "#Set the parameters of each model by cross-validation gridsearch\n",
    "#from custom-perceptron import my_perceptron\n",
    "models = {'KNN': KNeighborsClassifier(),\n",
    "          'OVR': OneVsRestClassifier(SVC()),\n",
    "        #   'GNB': OneVsRestClassifier(GaussianNB()),\n",
    "          'DT': DecisionTreeClassifier(),\n",
    "          'RF': RandomForestClassifier(n_jobs=-1), \n",
    "          'MLP': MLPClassifier(learning_rate='adaptive',shuffle=True, max_iter=500),\n",
    "          'XGB': XGBClassifier()}\n",
    "\n",
    "param_grid = [{'KNN__n_neighbors': [1, 3, 5, 7, 9, 11, 13, 15], 'KNN__weights': ['uniform', 'distance']},\n",
    "              {'OVR__estimator__kernel': ['rbf', 'linear'], 'OVR__estimator__gamma': ['scale', 'auto'],\n",
    "                'OVR__estimator__C': [10, 100, 1000]},\n",
    "            #   {'GNB__priors':[None, [0.5,0.5], [0.1, 0.9], [0.000001,0.99999], [0.000000001,0.99999999]]},\n",
    "              {'DT__criterion': ['entropy'], 'DT__max_depth': [6], 'DT__min_samples_leaf': [1], 'DT__min_samples_split': [4]},\n",
    "              {'RF__n_estimators': [200, 600], 'RF__max_depth': [4, 10, None], 'RF__min_samples_leaf': [1, 2, 5]},\n",
    "              {'MLP__hidden_layer_sizes': [150,100,50], 'MLP__activation':['relu','logistic','tanh'], \n",
    "               'MLP__solver': ['adam','lbfgs','sgd']}, #,verbose=True, early_stopping=True\n",
    "              {'XGB__learning_rate': [.1,.2,.3], 'XGB__max_depth': [1, 2, 3, 4, 5, 6],\n",
    "               'XGB__min_child_weight': [1,2],'XGB__subsample': [1.0, 0.5, 0.1],\n",
    "               'XGB__n_estimators': [200, 600]}]\n",
    "\n",
    "best_scores=[]\n",
    "params=[]\n",
    "\n",
    "for (classifier, model_params, name) in list(zip(models.values(), param_grid, models.keys())):\n",
    "    print(classifier, model_params, name)\n",
    "    print(f\"\\n\\nTuning hyper-parameters, based on accuracy for {name} with parameter grid:\\n {model_params}\\n\")\n",
    "\n",
    "    pipe = Pipeline([(name, models[name])])\n",
    "    clf = GridSearchCV(estimator=pipe, param_grid=model_params, cv=5, scoring='accuracy', n_jobs=-1)    \n",
    "    clf.fit(train_X, train_Y) \n",
    "\n",
    "    print(f\"Mean performance of each parameter combination based on Cross Validation\")\n",
    "    performance = pd.DataFrame(clf.cv_results_['params'])\n",
    "    performance[\"Score\"] = clf.cv_results_['mean_test_score']\n",
    "    print(performance)\n",
    "\n",
    "    print(\"\\nBest parameters set found on training set:\")\n",
    "    print(clf.best_params_)\n",
    "    params.append(clf.best_params_)\n",
    "\n",
    "    print(\"\\nThe scores are computed on the full evaluation set:\")\n",
    "    #evaluate and store scores of estimators of each category on validation set\n",
    "    score = clf.score(test_X, test_Y)\n",
    "    print(\"Accuracy:\", score)\n",
    "    best_scores.append(score)\n",
    "\n",
    "    pred_Y = clf.predict(test_X)\n",
    "    print(metrics.classification_report(test_Y, pred_Y, digits=5))\n",
    "    # cm = confusion_matrix(test_Y, pred_Y); plt.figure()\n",
    "    # plot_confusion_matrix(cm, classes=[0,1], title=name, cmap=plt.cm.Greens)\n",
    "    # print(\"True Positives: {}, False Positives: {}, True Negatives: {}, False Negatives: {} \\n\\n\".format(cm[0,0], cm[0,1], cm[1,1], cm[1,0]))\n",
    "\n",
    "final_scores = dict(zip(list(models.keys()), best_scores))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'KNN': 0.425, 'OVR': 0.55, 'DT': 0.4, 'RF': 0.45, 'MLP': 0.45, 'XGB': 0.475}\n"
     ]
    }
   ],
   "source": [
    "print(final_scores)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
